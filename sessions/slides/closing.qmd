---
title: "End of course summary"
author: "Understanding, evaluating, and improving forecasts of infectious disease burden"
engine: knitr
format:
  revealjs:
    output: slides/closing.html
    footer: "End of course summary"
    slide-level: 3
---

### Learning objectives

- improve understanding of forecasting as an epidemiological task
- familiarity with metrics for evaluating probabilistic forecasts and their properties
- ability to score probabilistic forecasts in R
- understanding of predictive ensembles and their properties
- ability to create a predictive ensemble of forecasts in R
- understanding the concept of weighted forecast ensembles

### Timeline

- forecast visualisation (session 1)
- forecast evaluation (session 2)
- forecast ensembles (sesion 3)

# Key takeaways

## Session 1: Forecasting {.smaller}

- **forecasting** is the task of making unconditional statements about the future
- meaningful forecasts are **probabilistic**
- we can use visualisation understand the predictive performance of a model

## Session 2: Forecast evaluation {.smaller}

- we can assess forecasts using **proper scoring rules**
- we can use scoring to quantify the predictive performance of different models

### Session 3: Forecast ensembles

- forecasts can combine **forecasts from multiple models** 
- simple ensembles often outperform indivdiual models
- weighted ensembles can learn from past performance aiming to make better forecasts

### Outlook {.smaller}

- it is worth trying some of these methods here in practice to learn more about typical forecast performance
- one way of doing so is by contributing to forecast hubs

![](figures/respicast.png)

[https://respicast.ecdc.europa.eu/](https://respicast.ecdc.europa.eu/)

### Feedback {.smaller}

- please tell us if you enjoyed the course, what worked / didn't work etc.
- we will send out a survey for feedback

# Thank you for attending!

[Return to the session](../end-of-course-summary-and-discussion)
