---
title: "Evaluating forecasts from multiple models"
order: 7
---

# Introduction

We can classify models along a spectrum by how much they include an understanding of underlying processes, or mechanisms; or whether they emphasise drawing from the data using a statistical approach.
These different approaches all have different strength and weaknesses, and it is not clear a prior which one produces the best forecast in any given situation.
One way to attempt to draw strength from a diversity of approaches is the creation of so-called *forecast ensembles* from the forecasts produced by different models.

In this session, we'll start with forecasts from models of different levels of mechanism vs. statistical complexity and build ensembles of these models.
We will then compare the performance of these ensembles to the individual models and to each other.
Rather than using the forecast samples we have been using we will instead now use quantile-based forecasts.

::: {.callout-note collapse="true"}
## Representations of probabilistic forecasts

Probabilistic predictions can be described as coming from a probabilistic probability distributions.
In general and when using complex models such as the one we discuss in this course, these distributions can not be expressed in a simple analytical formal as we can do if, e.g. talking about common probability distributions such as the normal or gamma distributions.
Instead, we typically use a limited number of samples generated from Monte-Carlo methods to represent the predictive distribution.
However, this is not the only way to characterise distributions.

A quantile is the value that corresponds to a given quantile level of a distribution.
For example, the median is the 50th quantile of a distribution, meaning that 50% of the values in the distribution are less than the median and 50% are greater.
Similarly, the 90th quantile is the value that corresponds to 90% of the distribution being less than this value.
If we characterise a predictive distribution by its quantiles, we specify these values at a range of specific quantile levels, e.g. from 5% to 95% in 5% steps.
:::

## Slides

- [Introduction to the spectrum of forecasting models](slides/introduction-to-the-spectrum-of-forecasting-models)

## Objectives

The aim of this session is to introduce the concept of a spectrum of forecasting models and to demonstrate how to evaluate a range of different models from across this spectrum.

::: {.callout-note collapse="true"}

# Setup

## Source file

The source file of this session is located at `sessions/forecast-ensembles.qmd`.

## Libraries used

In this session we will use the `nfidd` package to load a data set of infection times and access stan models and helper functions, the `dplyr`  and `tidyr` packages for data wrangling, `ggplot2` library for plotting, the `tidybayes` package for extracting results of the inference and the `scoringutils` package for evaluating forecasts.
We will also use `qra` for quantile regression averaging in the weighted ensemble section.

```{r libraries, message = FALSE}
library("nfidd")
library("dplyr")
library("tidyr")
library("ggplot2")
library("scoringutils")
library("qra")
```

::: {.callout-tip}
The best way to interact with the material is via the [Visual Editor](https://docs.posit.co/ide/user/ide/guide/documents/visual-editor.html) of RStudio.
:::

## Initialisation

We set a random seed for reproducibility.
Setting this ensures that you should get exactly the same results on your computer as we do.

```{r}
set.seed(123)
```

:::

# Individual forecast models

In this session we will use the forecasts from different models. There all shared the same basic renewal with delays structure but used different models for the evolution of the effective reproduction number over time. These were:

- A random walk model (what we have looked at so far)
- A simple model of susceptible depletion referred to as "More mechanistic"
- A differenced autoregressive model referred to as "More statistical"

For the purposes of this session the precise details of the models are not critical to the concepts we are exploring.


::: {.callout-note collapse="true"}

## More information on the mechanistic model (optional)
One way to potentially improve the renewal model is to add more mechanistic structure. In the [forecasting concepts session](forecasting-concepts), we saw that the renewal model was making unbiased forecasts when the reproduction number was constant but that it overestimated the number of cases when the reproduction number was reducing due to susceptible depletion.

::: {.callout-warning}
This is slightly cheating as we know the future of this outbreak and so can make a model to match. This is easy to do and important to watch for if wanting to make generalisable methods.
:::

This suggests that we should add a term to the renewal model which captures the depletion of susceptibles. One way to do this is to add a term which is proportional to the number of susceptibles in the population. This is the idea behind the _SIR model_ which is a simple compartmental model of infectious disease transmission. If we assume that susceptible depletion is the only mechanism which is causing the reproduction number to change, we can write the reproduction model as:

$$
R_t = \frac{S_{t-1}}{N} R_0
$$

::: {.callout-note}
This approximates susceptible depletion as a linear function of the number of susceptibles in the population. This is a simplification but it is a good starting point.
:::

::: {.callout-note collapse="true"}

## What behaviour would we expect from this model?

```{r}
n <- 100
N <- 1000
R0 <- 1.5
S <- rep(NA, n)
S[1] <- N
Rt <- rep(NA, n) ## reproduction number
Rt[1] <- R0
I <- rep(NA, n)
I[1] <- 1
for (i in 2:n) {
  Rt[i] <- (S[i-1]) / N * R0
  I[i] <- I[i-1] * Rt[i]
  S[i] <- S[i-1] - I[i]
}

data <- tibble(t = 1:n, Rt = Rt)

ggplot(data, aes(x = t, y = Rt)) +
  geom_line() +
  labs(title = "Simulated data from an SIR model",
       x = "Time",
       y = "Rt")
```
:::

The key assumptions we are making here are:

- The population is constant and we roughly know the size of the population.
- The reproduction number only changes due to susceptible depletion
- The number of new cases at each time is proportional to the number of susceptibles in the population.

:::

::: {.callout-note collapse="true"}
## More information on the statistical model (optional)

Adding more mechanistic structure is not always possible and, if we don't specify mechanisms correctly, might make forecasts worse.
Rather than adding more mechanistic structure to the renewal model, we could add more statistical structure with the aim of improving performance.
Before we do this, we need to think about what we want from a forecasting model.
As we identified above, we want a model which is unbiased and which has good short-term forecasting properties.
We know that we want it to be able to adapt to trends in the reproduction number and that we want it to be able to capture the noise in the data.
A statistical term that can be used to describe a time series with a trend is saying that the time series is _non-stationary_.
More specifically, a _stationary_ time series is defined as one whose statistical properties, such as mean and variance, do not change over time.
In infectious disease epidemiology, this would only be expected for endemic diseases without external seasonal influence.

The random walk model we used in the [forecasting visualisation session](forecast-visualisation) is a special case of a more general class of models called _autoregressive (AR) models_.
AR models are a class of models which predict the next value in a time series as a linear combination of the previous values in the time series.
The random walk model is specifically a special case of an AR(1) model where the next value in the time series is predicted as the previous value, multiplied by a value between 1 and -1 , plus some noise. This becomes a random walk when the multipled value is 0.

 For the log-transformed reproduction number ($log(R_t)$), the model is:

$$
log(R_t) = \phi log(R_{t-1}) + \epsilon_t
$$

where $\epsilon_t$ is a normally distributed error term with mean 0 and standard deviation $\sigma$ and $\phi$ is a parameter between -1 and 1. If we restrict $\phi$ to be between 0 and 1, we get a model which is biased towards a reproduction number of 1 but which can still capture trends in the data that decay over time.

::: {.callout-note collapse="true"}
## What behaviour would we expect from this model?

```{r}
n <- 100
phi <- 0.4
sigma <- 0.1
log_R <- rep(NA, n)
log_R[1] <- rnorm(1, 0, sigma)
for (i in 2:n) {
  log_R[i] <- phi * log_R[i-1] + rnorm(1, 0, sigma)
}
data <- tibble(t = 1:n, R = exp(log_R))

ggplot(data, aes(x = t, y = R)) +
  geom_line() +
  labs(title = "Simulated data from an exponentiated AR(1) model",
       x = "Time",
       y = "R")
```
:::

However, we probably don't want a model which is biased towards a reproduction number of 1 (unless we have good reason to believe that is the expected behaviour). So what should we do?

Returning to the idea that the reproduction number is a _non-stationary_ time series, as we expect to have a trend in the reproduction numbers we want to capture, we can use a method from the field of time series analysis called _differencing_ to make the time series stationary. This involves taking the difference between consecutive values in the time series. For the log-transformed reproduction number, this would be:

$$
log(R_t) - log(R_{t-1}) = \phi (log(R_{t-1}) - log(R_{t-2})) + \epsilon_t
$$

::: {.callout-note collapse="true"}
## What behaviour would we expect from this model?

Again we look at an R function that implements this model:

```{r geometric-diff-ar}
geometric_diff_ar
```

We can use this function to simulate a differenced AR process:

```{r}
log_R <- geometric_diff_ar(init = 1, noise = rnorm(100), std = 0.1, damp = 0.1)

data <- tibble(t = seq_along(log_R), R = exp(log_R))

ggplot(data, aes(x = t, y = R)) +
  geom_line() +
  labs(title = "Simulated data from an exponentiated AR(1) model with differencing",
       x = "Time",
       y = "R")
```

:::

:::

As previously, we have fitted these models to a range of forecast dates so you don't have to wait for the models to fit.
We will now evaluate the forecasts from the mechanistic and statistical models.

```{r load_forecasts}
data(rw_forecasts, stat_forecasts, mech_forecasts)
forecasts <- bind_rows(
  rw_forecasts,
  mutate(stat_forecasts, model = "More statistical"),
  mutate(mech_forecasts, model = "More mechanistic")
) |>
  ungroup()

forecasts
```

::: {.callout-tip collapse="true"}
## How did we generate these forecasts?
Some important things to note about these forecasts:

  - We used a 14 day forecast horizon.
  - Each forecast used all the data up to the forecast date.
  - We generated 1000 predictive posterior samples for each forecast.
  - We started forecasting 3 weeks into the outbreak and then forecast every 7 days until the end of the data (excluding the last 14 days to allow a full forecast).
  - We use the same simulated outbreak data as before:

```{r}
gen_time_pmf <- make_gen_time_pmf()
ip_pmf <- make_ip_pmf()
onset_df <- simulate_onsets(
  make_daily_infections(infection_times), gen_time_pmf, ip_pmf
)
head(onset_df)
```

:::

# Converting sample-based forecasts to quantile-based forecasts

As in this session we will be thinking about forecasts in terms quantiles of the predictive distributions, we will need to convert our sample based forecasts to quantile-based forecasts.
We will do this by focusing at the *marginal distribution* at each predicted time point, that is we treat each time point as independent of all others and calculate quantiles based on the sample predictive trajectories at that time point.
An easy way to do this is to use the `{scoringutils}` package.
The steps to do this are to first declare the forecasts as `sample` forecasts.

```{r convert-for-scoringutils}
sample_forecasts <- forecasts |>
  left_join(onset_df, by = "day") |>
  filter(!is.na(.value)) |>
  as_forecast_sample(
    forecast_unit = c("target_day", "horizon", "model", "day"),
    observed = "onsets",
    predicted = ".value",
    sample_id = ".draw"
  )
sample_forecasts
```

and then convert to `quantile` forecasts.

```{r convert-to-quantile}
quantile_forecasts <- sample_forecasts |>
  as_forecast_quantile()
quantile_forecasts
```

::: {.callout-tip collapse="true"}
## What is happening here?

- Internally `scoringutils` is calculating the quantiles of the sample-based forecasts.
- It does this by using a set of default quantiles but different ones can be specified by the user to override the default.
- It then calls the `quantile()` function from base R to calculate the quantiles.
- This is estimating the value that corresponds to each given quantile level by ordering the samples and then taking the value at the appropriate position.
:::

# Going further

# Wrap up

# References

::: {#refs}
:::
